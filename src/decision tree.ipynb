{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andromeda\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "\n",
    "import gc\n",
    "\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import optimizers\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions:\n",
    "<pre>\n",
    "Resetting model and log directory\n",
    "class name cleansing\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make or reset directory\n",
    "def mk_reset_dir(directory):\n",
    "    if os.path.exists(directory):\n",
    "        try:\n",
    "            shutil.rmtree(directory)\n",
    "            os.mkdir(directory)\n",
    "        except:\n",
    "            print(\"error:\", directory)\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory)\n",
    "        except:\n",
    "            print(\"error create:\", directory)\n",
    "            \n",
    "\n",
    "def name_correct(name):\n",
    "    return re.sub(r'[^a-zA-Z,:]', ' ', name).title()\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Data / Output Directory\n",
    "<pre>\n",
    "Data             : training, validation, testing\n",
    "Model and output : model directory and logs directory\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting data path data seperated by class name\n",
    "training_dir = r\"data/input/train\"\n",
    "testing_dir = r\"data/input/test\"\n",
    "validation_dir = r'data/input/validation'\n",
    "\n",
    "# setting output directory\n",
    "model_dir = r\"data/output/models/\"\n",
    "log_dir = r\"data/output/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resetting Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mk_reset_dir(model_dir)\n",
    "# mk_reset_dir(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Parameters for Image Transformation\n",
    "Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of class\n",
    "num_class = len(os.listdir(training_dir))\n",
    "\n",
    "# setting training parameters\n",
    "norm = 255.0\n",
    "rescale=1./norm\n",
    "shear_range=0.2\n",
    "zoom_range=0.2\n",
    "horizontal_flip=True\n",
    "\n",
    "# setting train, test, validation parameters\n",
    "target_size=(224, 224)\n",
    "# batch_size=32\n",
    "batch_size=64\n",
    "class_mode='categorical'\n",
    "\n",
    "loss='categorical_crossentropy'\n",
    "# metrics=['accuracy', 'binary_accuracy', precision, recall]\n",
    "metrics=['accuracy']\n",
    "\n",
    "epochs = 50\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/output/models/{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file = model_dir+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "# model_file = \"weights-{epoch:02d}-val_acc-{val_acc:.2f}.hdf5\"\n",
    "model_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Image Dataset for Training, Validation, Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing inception model\n",
    "base_model = DecisionTreeClassifier(weights='imagenet', include_top=False)\n",
    "\n",
    "# setting model layers specially output layer with class number\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_class, activation='softmax')(x)\n",
    "\n",
    "#loading model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "#print layers of inception model\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#     print(i, layer.name)\n",
    "    \n",
    "    \n",
    "# set all laeyrs as untrainable\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# train the top inception layers \n",
    "# freeze first 249 layers\n",
    "# unfreeze the rest\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "# set optimizer\n",
    "sgd = optimizers.Adam()\n",
    "# sgd = optimizers.Adam(lr=0.001)\n",
    "# sgd = optimizers.Adam(lr=0.0001)\n",
    "# sgd = optimizers.SGD()\n",
    "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# sgd = optimizer=SGD(lr=0.0001, momentum=0.9)\n",
    "\n",
    "# compile model with optimizer and loss\n",
    "model.compile(sgd, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(model_file, monitor='val_acc', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None)\n",
    "# early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto', baseline=None)\n",
    "# early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None)\n",
    "\n",
    "# tensorboard = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0, batch_size=1, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None)\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0, batch_size=batch_size, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None)\n",
    "# tensorboard = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, batch_size=32, write_graph=True, write_grads=False, write_images=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None)\n",
    "\n",
    "tensorboard.set_model(model) \n",
    "\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.0001)\n",
    "\n",
    "# callbacks_list = [checkpoint, tensorboard, early_stopping]\n",
    "# callbacks_list = [reduce_lr, checkpoint, tensorboard, early_stopping]\n",
    "callbacks_list = [reduce_lr, checkpoint, tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training \n",
    "#### Training model with given parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "113/113 [==============================] - 309s 3s/step - loss: 2.4870 - acc: 0.3895 - val_loss: 2.6569 - val_acc: 0.4366\n",
      "Epoch 2/50\n",
      "113/113 [==============================] - 90s 799ms/step - loss: 1.4290 - acc: 0.5986 - val_loss: 1.9704 - val_acc: 0.5350\n",
      "Epoch 3/50\n",
      "113/113 [==============================] - 89s 789ms/step - loss: 1.0519 - acc: 0.6926 - val_loss: 1.9324 - val_acc: 0.5374\n",
      "Epoch 4/50\n",
      "113/113 [==============================] - 89s 785ms/step - loss: 0.7961 - acc: 0.7539 - val_loss: 2.1721 - val_acc: 0.5193\n",
      "Epoch 5/50\n",
      "113/113 [==============================] - 89s 791ms/step - loss: 0.6047 - acc: 0.8147 - val_loss: 2.0478 - val_acc: 0.5233\n",
      "Epoch 6/50\n",
      "113/113 [==============================] - 91s 805ms/step - loss: 0.5287 - acc: 0.8358 - val_loss: 2.0825 - val_acc: 0.5394\n",
      "Epoch 7/50\n",
      "113/113 [==============================] - 92s 815ms/step - loss: 0.4221 - acc: 0.8668 - val_loss: 2.0232 - val_acc: 0.5614\n",
      "Epoch 8/50\n",
      "113/113 [==============================] - 92s 816ms/step - loss: 0.3391 - acc: 0.8960 - val_loss: 2.4845 - val_acc: 0.5296\n",
      "Epoch 9/50\n",
      "113/113 [==============================] - 93s 823ms/step - loss: 0.1817 - acc: 0.9444 - val_loss: 1.5242 - val_acc: 0.6476\n",
      "Epoch 10/50\n",
      "113/113 [==============================] - 92s 818ms/step - loss: 0.0892 - acc: 0.9742 - val_loss: 1.5141 - val_acc: 0.6598\n",
      "Epoch 11/50\n",
      "113/113 [==============================] - 94s 831ms/step - loss: 0.0633 - acc: 0.9831 - val_loss: 1.5466 - val_acc: 0.6628\n",
      "Epoch 12/50\n",
      "113/113 [==============================] - 92s 815ms/step - loss: 0.0576 - acc: 0.9826 - val_loss: 1.5341 - val_acc: 0.6667\n",
      "Epoch 13/50\n",
      "113/113 [==============================] - 92s 818ms/step - loss: 0.0498 - acc: 0.9867 - val_loss: 1.5678 - val_acc: 0.6637\n",
      "Epoch 14/50\n",
      "113/113 [==============================] - 93s 820ms/step - loss: 0.0434 - acc: 0.9878 - val_loss: 1.5895 - val_acc: 0.6701\n",
      "Epoch 15/50\n",
      "113/113 [==============================] - 92s 818ms/step - loss: 0.0301 - acc: 0.9926 - val_loss: 1.5727 - val_acc: 0.6657\n",
      "Epoch 16/50\n",
      "113/113 [==============================] - 93s 825ms/step - loss: 0.0320 - acc: 0.9925 - val_loss: 1.6124 - val_acc: 0.6628\n",
      "Epoch 17/50\n",
      "113/113 [==============================] - 92s 813ms/step - loss: 0.0343 - acc: 0.9900 - val_loss: 1.6315 - val_acc: 0.6583\n",
      "Epoch 18/50\n",
      "113/113 [==============================] - 93s 826ms/step - loss: 0.0312 - acc: 0.9912 - val_loss: 1.6586 - val_acc: 0.6662\n",
      "Epoch 19/50\n",
      "113/113 [==============================] - 92s 815ms/step - loss: 0.0249 - acc: 0.9939 - val_loss: 1.6731 - val_acc: 0.6647\n",
      "Epoch 20/50\n",
      "113/113 [==============================] - 92s 815ms/step - loss: 0.0288 - acc: 0.9916 - val_loss: 1.6755 - val_acc: 0.6613\n",
      "Epoch 21/50\n",
      "113/113 [==============================] - 92s 810ms/step - loss: 0.0231 - acc: 0.9933 - val_loss: 1.6881 - val_acc: 0.6647\n",
      "Epoch 22/50\n",
      "113/113 [==============================] - 93s 820ms/step - loss: 0.0208 - acc: 0.9944 - val_loss: 1.7261 - val_acc: 0.6637\n",
      "Epoch 23/50\n",
      "113/113 [==============================] - 93s 826ms/step - loss: 0.0172 - acc: 0.9960 - val_loss: 1.7409 - val_acc: 0.6598\n",
      "Epoch 24/50\n",
      "113/113 [==============================] - 94s 833ms/step - loss: 0.0175 - acc: 0.9951 - val_loss: 1.7480 - val_acc: 0.6672\n",
      "Epoch 25/50\n",
      "113/113 [==============================] - 96s 847ms/step - loss: 0.0201 - acc: 0.9943 - val_loss: 1.8627 - val_acc: 0.6613\n",
      "Epoch 26/50\n",
      "113/113 [==============================] - 95s 838ms/step - loss: 0.0196 - acc: 0.9932 - val_loss: 1.8163 - val_acc: 0.6618\n",
      "Epoch 27/50\n",
      "113/113 [==============================] - 94s 834ms/step - loss: 0.0164 - acc: 0.9949 - val_loss: 1.8127 - val_acc: 0.6618\n",
      "Epoch 28/50\n",
      "113/113 [==============================] - 93s 825ms/step - loss: 0.0157 - acc: 0.9950 - val_loss: 1.7982 - val_acc: 0.6628\n",
      "Epoch 29/50\n",
      "113/113 [==============================] - 94s 830ms/step - loss: 0.0179 - acc: 0.9936 - val_loss: 1.8818 - val_acc: 0.6564\n",
      "Epoch 30/50\n",
      "113/113 [==============================] - 93s 824ms/step - loss: 0.0174 - acc: 0.9943 - val_loss: 1.8187 - val_acc: 0.6593\n",
      "Epoch 31/50\n",
      "113/113 [==============================] - 93s 824ms/step - loss: 0.0118 - acc: 0.9973 - val_loss: 1.8065 - val_acc: 0.6652\n",
      "Epoch 32/50\n",
      "113/113 [==============================] - 93s 827ms/step - loss: 0.0144 - acc: 0.9954 - val_loss: 1.8477 - val_acc: 0.6725\n",
      "Epoch 33/50\n",
      "113/113 [==============================] - 93s 822ms/step - loss: 0.0202 - acc: 0.9933 - val_loss: 1.9076 - val_acc: 0.6628\n",
      "Epoch 34/50\n",
      "113/113 [==============================] - 93s 822ms/step - loss: 0.0153 - acc: 0.9956 - val_loss: 2.0286 - val_acc: 0.6471\n",
      "Epoch 35/50\n",
      "113/113 [==============================] - 93s 827ms/step - loss: 0.0122 - acc: 0.9964 - val_loss: 1.9238 - val_acc: 0.6530\n",
      "Epoch 36/50\n",
      "113/113 [==============================] - 93s 823ms/step - loss: 0.0112 - acc: 0.9960 - val_loss: 1.9605 - val_acc: 0.6525\n",
      "Epoch 37/50\n",
      "113/113 [==============================] - 93s 822ms/step - loss: 0.0107 - acc: 0.9967 - val_loss: 2.0013 - val_acc: 0.6461\n",
      "Epoch 38/50\n",
      "113/113 [==============================] - 93s 824ms/step - loss: 0.0169 - acc: 0.9947 - val_loss: 2.0451 - val_acc: 0.6486\n",
      "Epoch 39/50\n",
      "113/113 [==============================] - 93s 821ms/step - loss: 0.0105 - acc: 0.9970 - val_loss: 2.0191 - val_acc: 0.6500\n",
      "Epoch 40/50\n",
      "113/113 [==============================] - 94s 833ms/step - loss: 0.0146 - acc: 0.9953 - val_loss: 2.0363 - val_acc: 0.6481\n",
      "Epoch 41/50\n",
      "113/113 [==============================] - 94s 835ms/step - loss: 0.0119 - acc: 0.9967 - val_loss: 2.0627 - val_acc: 0.6471\n",
      "Epoch 42/50\n",
      "113/113 [==============================] - 96s 845ms/step - loss: 0.0134 - acc: 0.9957 - val_loss: 2.0486 - val_acc: 0.6442\n",
      "Epoch 43/50\n",
      "113/113 [==============================] - 95s 839ms/step - loss: 0.0080 - acc: 0.9974 - val_loss: 2.0701 - val_acc: 0.6456\n",
      "Epoch 44/50\n",
      "113/113 [==============================] - 95s 842ms/step - loss: 0.0094 - acc: 0.9974 - val_loss: 1.9584 - val_acc: 0.6569\n",
      "Epoch 45/50\n",
      "113/113 [==============================] - 94s 833ms/step - loss: 0.0095 - acc: 0.9971 - val_loss: 2.0471 - val_acc: 0.6486\n",
      "Epoch 46/50\n",
      "113/113 [==============================] - 93s 823ms/step - loss: 0.0103 - acc: 0.9964 - val_loss: 2.0542 - val_acc: 0.6510\n",
      "Epoch 47/50\n",
      "113/113 [==============================] - 94s 833ms/step - loss: 0.0141 - acc: 0.9957 - val_loss: 2.1191 - val_acc: 0.6432\n",
      "Epoch 48/50\n",
      "113/113 [==============================] - 94s 832ms/step - loss: 0.0139 - acc: 0.9953 - val_loss: 2.1340 - val_acc: 0.6407\n",
      "Epoch 49/50\n",
      "113/113 [==============================] - 98s 865ms/step - loss: 0.0118 - acc: 0.9968 - val_loss: 2.0331 - val_acc: 0.6481\n",
      "Epoch 50/50\n",
      "113/113 [==============================] - 91s 806ms/step - loss: 0.0104 - acc: 0.9964 - val_loss: 2.1411 - val_acc: 0.6270\n"
     ]
    }
   ],
   "source": [
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch = len(train_generator),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
