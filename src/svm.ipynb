{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andromeda\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "\n",
    "import gc\n",
    "\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import optimizers\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions:\n",
    "<pre>\n",
    "Resetting model and log directory\n",
    "class name cleansing\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make or reset directory\n",
    "def mk_reset_dir(directory):\n",
    "    if os.path.exists(directory):\n",
    "        try:\n",
    "            shutil.rmtree(directory)\n",
    "            os.mkdir(directory)\n",
    "        except:\n",
    "            print(\"error:\", directory)\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory)\n",
    "        except:\n",
    "            print(\"error create:\", directory)\n",
    "            \n",
    "\n",
    "def name_correct(name):\n",
    "    return re.sub(r'[^a-zA-Z,:]', ' ', name).title()\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Data / Output Directory\n",
    "<pre>\n",
    "Data             : training, validation, testing\n",
    "Model and output : model directory and logs directory\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting data path data seperated by class name\n",
    "training_dir = r\"data/input/train\"\n",
    "testing_dir = r\"data/input/test\"\n",
    "validation_dir = r'data/input/validation'\n",
    "\n",
    "# setting output directory\n",
    "model_dir = r\"data/output/models/\"\n",
    "log_dir = r\"data/output/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resetting Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mk_reset_dir(model_dir)\n",
    "# mk_reset_dir(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Parameters for Image Transformation\n",
    "Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of class\n",
    "num_class = len(os.listdir(training_dir))\n",
    "\n",
    "# setting training parameters\n",
    "norm = 255.0\n",
    "rescale=1./norm\n",
    "shear_range=0.2\n",
    "zoom_range=0.2\n",
    "horizontal_flip=True\n",
    "\n",
    "# setting train, test, validation parameters\n",
    "target_size=(224, 224)\n",
    "# batch_size=32\n",
    "batch_size=64\n",
    "class_mode='categorical'\n",
    "\n",
    "loss='categorical_crossentropy'\n",
    "# metrics=['accuracy', 'binary_accuracy', precision, recall]\n",
    "metrics=['accuracy']\n",
    "\n",
    "epochs = 50\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/output/models/{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file = model_dir+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "# model_file = \"weights-{epoch:02d}-val_acc-{val_acc:.2f}.hdf5\"\n",
    "model_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Image Dataset for Training, Validation, Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3031 images belonging to 5 classes.\n",
      "Found 866 images belonging to 5 classes.\n",
      "Found 426 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# data generator for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=rescale,\n",
    "        shear_range=shear_range,\n",
    "        zoom_range=zoom_range,\n",
    "        horizontal_flip=horizontal_flip)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        training_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode)\n",
    "\n",
    "# data generator for validation\n",
    "validation_datagen = ImageDataGenerator(rescale=rescale)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode)\n",
    "\n",
    "# data generator for testing\n",
    "test_datagen = ImageDataGenerator(rescale=rescale)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        testing_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing inception model\n",
    "base_model = SupportVectorMachine(weights='imagenet', include_top=False)\n",
    "\n",
    "# setting model layers specially output layer with class number\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_class, activation='softmax')(x)\n",
    "\n",
    "#loading model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "#print layers of inception model\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#     print(i, layer.name)\n",
    "    \n",
    "    \n",
    "# set all laeyrs as untrainable\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# train the top inception layers \n",
    "# freeze first 249 layers\n",
    "# unfreeze the rest\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "# set optimizer\n",
    "sgd = optimizers.Adam()\n",
    "# sgd = optimizers.Adam(lr=0.001)\n",
    "# sgd = optimizers.Adam(lr=0.0001)\n",
    "# sgd = optimizers.SGD()\n",
    "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# sgd = optimizer=SGD(lr=0.0001, momentum=0.9)\n",
    "\n",
    "# compile model with optimizer and loss\n",
    "model.compile(sgd, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CheckPoint, and Callbacks (TensorBoard, Early Stopping, Reduce Learning rate) Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(model_file, monitor='val_acc', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None)\n",
    "# early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto', baseline=None)\n",
    "# early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None)\n",
    "\n",
    "# tensorboard = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0, batch_size=1, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None)\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0, batch_size=batch_size, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None)\n",
    "# tensorboard = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, batch_size=32, write_graph=True, write_grads=False, write_images=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None)\n",
    "\n",
    "tensorboard.set_model(model) \n",
    "\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.0001)\n",
    "\n",
    "# callbacks_list = [checkpoint, tensorboard, early_stopping]\n",
    "# callbacks_list = [reduce_lr, checkpoint, tensorboard, early_stopping]\n",
    "callbacks_list = [reduce_lr, checkpoint, tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training \n",
    "#### Training model with given parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "48/48 [==============================] - 50s 1s/step - loss: 0.6101 - acc: 0.7993 - val_loss: 1.9106 - val_acc: 0.7125\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 33s 690ms/step - loss: 0.2757 - acc: 0.9051 - val_loss: 1.0942 - val_acc: 0.7956\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 38s 796ms/step - loss: 0.1923 - acc: 0.9379 - val_loss: 2.0963 - val_acc: 0.6663\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 38s 798ms/step - loss: 0.1433 - acc: 0.9550 - val_loss: 0.6900 - val_acc: 0.8406\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 38s 785ms/step - loss: 0.1179 - acc: 0.9606 - val_loss: 0.7516 - val_acc: 0.8360\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 38s 792ms/step - loss: 0.1068 - acc: 0.9681 - val_loss: 1.2582 - val_acc: 0.7425\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 37s 765ms/step - loss: 0.0712 - acc: 0.9756 - val_loss: 0.9081 - val_acc: 0.7887\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 38s 784ms/step - loss: 0.0661 - acc: 0.9766 - val_loss: 1.5514 - val_acc: 0.7159\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 37s 765ms/step - loss: 0.0803 - acc: 0.9752 - val_loss: 1.2528 - val_acc: 0.8048\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 36s 749ms/step - loss: 0.0457 - acc: 0.9834 - val_loss: 0.8488 - val_acc: 0.8303\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 43s 904ms/step - loss: 0.0422 - acc: 0.9884 - val_loss: 0.7320 - val_acc: 0.8326\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 39s 820ms/step - loss: 0.0236 - acc: 0.9932 - val_loss: 0.6461 - val_acc: 0.8441\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 45s 933ms/step - loss: 0.0210 - acc: 0.9935 - val_loss: 0.6190 - val_acc: 0.8406\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 39s 809ms/step - loss: 0.0155 - acc: 0.9945 - val_loss: 0.6093 - val_acc: 0.8476\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 43s 886ms/step - loss: 0.0119 - acc: 0.9954 - val_loss: 0.6197 - val_acc: 0.8499\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 41s 859ms/step - loss: 0.0107 - acc: 0.9964 - val_loss: 0.6305 - val_acc: 0.8441\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 41s 855ms/step - loss: 0.0119 - acc: 0.9951 - val_loss: 0.6442 - val_acc: 0.8453\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 42s 879ms/step - loss: 0.0106 - acc: 0.9958 - val_loss: 0.6463 - val_acc: 0.8453\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 44s 909ms/step - loss: 0.0098 - acc: 0.9964 - val_loss: 0.6412 - val_acc: 0.8430\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 41s 859ms/step - loss: 0.0106 - acc: 0.9961 - val_loss: 0.6437 - val_acc: 0.8499\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 41s 860ms/step - loss: 0.0091 - acc: 0.9977 - val_loss: 0.6551 - val_acc: 0.8499\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 41s 856ms/step - loss: 0.0096 - acc: 0.9962 - val_loss: 0.6881 - val_acc: 0.8487\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 43s 906ms/step - loss: 0.0142 - acc: 0.9943 - val_loss: 0.6670 - val_acc: 0.8487\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 42s 865ms/step - loss: 0.0099 - acc: 0.9967 - val_loss: 0.6980 - val_acc: 0.8487\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 44s 908ms/step - loss: 0.0090 - acc: 0.9959 - val_loss: 0.7237 - val_acc: 0.8476\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 41s 852ms/step - loss: 0.0080 - acc: 0.9974 - val_loss: 0.7529 - val_acc: 0.8510\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 42s 877ms/step - loss: 0.0131 - acc: 0.9953 - val_loss: 0.7747 - val_acc: 0.8430\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 43s 906ms/step - loss: 0.0105 - acc: 0.9964 - val_loss: 0.7712 - val_acc: 0.8418\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 41s 846ms/step - loss: 0.0095 - acc: 0.9962 - val_loss: 0.7497 - val_acc: 0.8464\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 42s 865ms/step - loss: 0.0085 - acc: 0.9971 - val_loss: 0.9030 - val_acc: 0.8210\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 43s 897ms/step - loss: 0.0089 - acc: 0.9971 - val_loss: 0.8669 - val_acc: 0.8314\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 42s 883ms/step - loss: 0.0067 - acc: 0.9964 - val_loss: 0.7854 - val_acc: 0.8441\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 37s 780ms/step - loss: 0.0334 - acc: 0.9938 - val_loss: 0.7255 - val_acc: 0.8557\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 42s 875ms/step - loss: 0.0057 - acc: 0.9980 - val_loss: 0.7644 - val_acc: 0.8499\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 38s 784ms/step - loss: 0.0129 - acc: 0.9958 - val_loss: 0.8061 - val_acc: 0.8360\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 40s 839ms/step - loss: 0.0058 - acc: 0.9977 - val_loss: 0.7988 - val_acc: 0.8499\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 40s 830ms/step - loss: 0.0122 - acc: 0.9958 - val_loss: 0.7533 - val_acc: 0.8568\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 39s 809ms/step - loss: 0.0057 - acc: 0.9974 - val_loss: 0.7764 - val_acc: 0.8522\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 44s 910ms/step - loss: 0.0054 - acc: 0.9967 - val_loss: 0.7878 - val_acc: 0.8441\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 39s 818ms/step - loss: 0.0049 - acc: 0.9977 - val_loss: 0.8564 - val_acc: 0.8395\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 40s 826ms/step - loss: 0.0048 - acc: 0.9977 - val_loss: 0.8574 - val_acc: 0.8383\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 39s 809ms/step - loss: 0.0046 - acc: 0.9984 - val_loss: 0.8222 - val_acc: 0.8580\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 44s 915ms/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.7971 - val_acc: 0.8649\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 42s 876ms/step - loss: 0.0049 - acc: 0.9977 - val_loss: 0.8200 - val_acc: 0.8522\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 41s 851ms/step - loss: 0.0051 - acc: 0.9977 - val_loss: 0.8201 - val_acc: 0.8545\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 45s 932ms/step - loss: 0.0053 - acc: 0.9971 - val_loss: 0.8018 - val_acc: 0.8591\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 40s 838ms/step - loss: 0.0057 - acc: 0.9971 - val_loss: 0.8177 - val_acc: 0.8591\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 43s 889ms/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.8939 - val_acc: 0.8499\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 41s 852ms/step - loss: 0.0067 - acc: 0.9974 - val_loss: 0.9448 - val_acc: 0.8222\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 40s 839ms/step - loss: 0.0031 - acc: 0.9977 - val_loss: 0.9171 - val_acc: 0.8314\n"
     ]
    }
   ],
   "source": [
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch = len(train_generator),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
